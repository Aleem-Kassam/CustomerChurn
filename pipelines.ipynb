{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning project -- Part 2  Build data Pipelines\n",
    "\n",
    "This project is to build a predictive machine learning model using the customer churn data available at Kaggle website. <br>\n",
    "Part 2 will look at building data pipelines that include engineering new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data nad split into train and test\n",
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (17654, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>vintage</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>occupation</th>\n",
       "      <th>customer_nw_category</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>days_since_last_transaction</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>previous_month_end_balance</th>\n",
       "      <th>average_monthly_balance_prevQ</th>\n",
       "      <th>average_monthly_balance_prevQ2</th>\n",
       "      <th>current_month_credit</th>\n",
       "      <th>previous_month_credit</th>\n",
       "      <th>current_month_debit</th>\n",
       "      <th>previous_month_debit</th>\n",
       "      <th>current_month_balance</th>\n",
       "      <th>previous_month_balance</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16405</th>\n",
       "      <td>22495.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Low</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5389.28</td>\n",
       "      <td>5524.81</td>\n",
       "      <td>6441.43</td>\n",
       "      <td>1849.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.10</td>\n",
       "      <td>78.96</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5450.94</td>\n",
       "      <td>5527.21</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>9585.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Medium</td>\n",
       "      <td>236.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23112.39</td>\n",
       "      <td>22701.04</td>\n",
       "      <td>22629.35</td>\n",
       "      <td>21324.33</td>\n",
       "      <td>411.84</td>\n",
       "      <td>411.84</td>\n",
       "      <td>0.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22555.07</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13313</th>\n",
       "      <td>18232.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2771.30</td>\n",
       "      <td>4585.75</td>\n",
       "      <td>3204.37</td>\n",
       "      <td>3343.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1971.76</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3341.84</td>\n",
       "      <td>3806.77</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>14534.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Low</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>18226.80</td>\n",
       "      <td>18226.80</td>\n",
       "      <td>8140.30</td>\n",
       "      <td>14407.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>16457.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>18226.80</td>\n",
       "      <td>4424.20</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>6508.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2785.53</td>\n",
       "      <td>2783.58</td>\n",
       "      <td>2784.07</td>\n",
       "      <td>4760.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2785.06</td>\n",
       "      <td>2783.58</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id  vintage   age  gender  dependents occupation  \\\n",
       "16405      22495.0   2690.0  60.0    Male         2.0   Engineer   \n",
       "7032        9585.0   1537.0  37.0  Female         0.0   Engineer   \n",
       "13313      18232.0   1212.0  86.0  Female         0.0   Engineer   \n",
       "10602      14534.0    310.0  43.0    Male         2.0   Engineer   \n",
       "4769        6508.0   1047.0  39.0  Female         0.0   Engineer   \n",
       "\n",
       "      customer_nw_category  branch_code  days_since_last_transaction  \\\n",
       "16405                  Low       1006.0                         56.0   \n",
       "7032                Medium        236.0                         26.0   \n",
       "13313               Medium         17.0                         73.0   \n",
       "10602                  Low       1712.0                         35.0   \n",
       "4769                Medium       1054.0                        230.0   \n",
       "\n",
       "       current_balance  previous_month_end_balance  \\\n",
       "16405          5389.28                     5524.81   \n",
       "7032          23112.39                    22701.04   \n",
       "13313          2771.30                     4585.75   \n",
       "10602         18226.80                    18226.80   \n",
       "4769           2785.53                     2783.58   \n",
       "\n",
       "       average_monthly_balance_prevQ  average_monthly_balance_prevQ2  \\\n",
       "16405                        6441.43                         1849.92   \n",
       "7032                        22629.35                        21324.33   \n",
       "13313                        3204.37                         3343.61   \n",
       "10602                        8140.30                        14407.70   \n",
       "4769                         2784.07                         4760.12   \n",
       "\n",
       "       current_month_credit  previous_month_credit  current_month_debit  \\\n",
       "16405                  0.53                  29.10                78.96   \n",
       "7032                 411.84                 411.84                 0.49   \n",
       "13313                  0.33                   0.33              1971.76   \n",
       "10602                  0.23               16457.37                 0.23   \n",
       "4769                   0.03                   0.03                 0.03   \n",
       "\n",
       "       previous_month_debit  current_month_balance  previous_month_balance  \\\n",
       "16405                  0.53                5450.94                 5527.21   \n",
       "7032                    NaN                    NaN                22555.07   \n",
       "13313                  0.33                3341.84                 3806.77   \n",
       "10602                  0.23               18226.80                 4424.20   \n",
       "4769                   0.03                2785.06                 2783.58   \n",
       "\n",
       "      churn  \n",
       "16405   Yes  \n",
       "7032    Yes  \n",
       "13313   Yes  \n",
       "10602   Yes  \n",
       "4769    Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in data\n",
    "df0 = pd.read_csv('./data/visathon_train_data.csv')#,index=customer_id)\n",
    "print('Shape: {}'.format(df0.shape))\n",
    "df0.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depend = ['dependents']\n",
    "cat_vars = ['gender', 'occupation']#,'branch_code']\n",
    "\n",
    "nw_cat = ['customer_nw_category']\n",
    "bal_vars = ['current_balance', 'current_month_balance', \n",
    "            'previous_month_end_balance','previous_month_balance',\n",
    "            'average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2']\n",
    "debit_vars = ['current_month_debit','previous_month_debit']\n",
    "credit_vars = ['current_month_credit', 'previous_month_credit']\n",
    "vin_age_vars = ['vintage', 'age']\n",
    "vin_day_vars = ['days_since_last_transaction','vintage']\n",
    "vin_dep_vars = ['dependents','vintage']\n",
    "\n",
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df0.drop(target,axis=1).copy()\n",
    "y = df0[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13240, 19)\n",
      "X_test shape: (4414, 19)\n",
      "y_train shape: (13240,)\n",
      "y_test shape: (4414,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=10086)\n",
    "print('X_train shape: {}\\nX_test shape: {}\\ny_train shape: {}\\ny_test shape: {}'.format( X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom functions\n",
    "### 1. Use BaseEstimator and TransformerMixin\n",
    "These transformers have been tested, can be used in the pipelines to replace corresponding tranformers from custom functions in following section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "## balance features\n",
    "class AmongFeaturesMeanImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column=[], features=[]):\n",
    "        \"\"\" column: feature to be imputed\n",
    "            features: features to for average values (can include column)\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        for feature in self.features:\n",
    "            X[feature].fillna(X[self.features].mean(axis=1,skipna=True),inplace=True)\n",
    "        return X\n",
    "\n",
    "# debit and credit features\n",
    "class FromFeatureImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=[]):\n",
    "        \"\"\" Column: feature to be imputed\n",
    "            feature: feature to provide value\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "#         self.column = column\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        print(self.features)\n",
    "        print([self.features[0]])\n",
    "        print(self.features + [self.features[0]])\n",
    "        feature_list = self.features + [self.features[0]]\n",
    "        for i, feature in enumerate(feature_list):\n",
    "            if i < len(feature_list)-1:\n",
    "                X[feature] = X[feature].fillna(X[feature_list[i+1]]*(1+np.random.randn()))\n",
    "        return X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define custom tranformation functions\n",
    "#### 1) Impute and log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine non-frequent categories into one\n",
    "def combine_cat(s, cutoff=6, replace=6):\n",
    "    \"\"\" Replace the categories that are greater than or equal to cutoff with value cat\n",
    "        s: a Pandas series\n",
    "        cutoff: a scalar\n",
    "        cat: scalar\n",
    "        \n",
    "        return: a series with replaced values\n",
    "    \"\"\"\n",
    "    s_ = s.copy()\n",
    "    mask = s > cutoff\n",
    "    s_[mask==True] = replace\n",
    "    return s_\n",
    "\n",
    "# balance, debit, credit, days_since_last_transaction\n",
    "def log_transform(df):\n",
    "#     print('This starts')\n",
    "#     print(df)\n",
    "#     print('this ends')\n",
    "    if df.size == len(df):\n",
    "        s = df\n",
    "        s_ = [np.log(x+1) if x>=0 else -np.log(-x+1) for x in s]\n",
    "    else:\n",
    "        s_= []\n",
    "        for i in range(df.shape[1]):\n",
    "            s = df.iloc[:,i] \n",
    "            s_.append([np.log(x+1) if x>=0 else -np.log(-x+1) for x in s])\n",
    "        s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_\n",
    "\n",
    "## balance features\n",
    "def impute_balance(df):\n",
    "    \"\"\" s: a panda series. To be imputed.\n",
    "        features: features to for average values (can include column)\n",
    "    \"\"\"\n",
    "    s_= []\n",
    "    for i in range(df.shape[1]):\n",
    "        s = df.iloc[:,i] \n",
    "        s_.append(s.fillna(df.mean(axis=1,skipna=True)))\n",
    "    s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_\n",
    "\n",
    "# debit and credit features\n",
    "def impute_credit_debit(df):\n",
    "    s_= []\n",
    "    for i in range(df.shape[1]):\n",
    "        s = df.iloc[:,i] \n",
    "        s_.append(s.fillna(df.mean(axis=1)*(1+np.random.randn())))\n",
    "    s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Engineer new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Engineer new features \n",
    "# percentage changes\n",
    "def calculate_pct_change(df):\n",
    "    \"\"\" calculate percent changes in balance between consecutive periods\n",
    "        df: Pandas dataframe or array. Balance columns of two consecutive peroids\n",
    "        \n",
    "        return: a series containing percent changes.\n",
    "    \"\"\"\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    s_ = []\n",
    "    for i in range(df_.shape[1]-1):\n",
    "        s1 = df_.iloc[:,i]\n",
    "        s2 = df_.iloc[:,i+1]\n",
    "        s_.append((s1-s2)/(s2+1)*100) # s2+1 to avoid dividing-by-zero\n",
    "    df_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return df_ \n",
    "\n",
    "# vintage/(day_since_last_transaction) & per person values in a household\n",
    "def calculate_ratio(df):\n",
    "    \"\"\" calculate the ratio of two features\n",
    "        s1, s2: Pandas series.\n",
    "        \n",
    "        return: a series containing ratio.\n",
    "    \"\"\"\n",
    "    s_ = []\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    s1 = df_.iloc[:,0]\n",
    "    for i in range(1,df_.shape[1]):\n",
    "        s2 = df_.iloc[:,i]\n",
    "        s_.append(s2/(s1+1)) #to avoid dividing by zero\n",
    "    df_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return df_ \n",
    "\n",
    "# vintage_age score 1 - equal distance\n",
    "def calculate_vintage_age_score_eqdist(df):\n",
    "    \"\"\" df: an array of shape (*,2)\n",
    "        df.shape[0]: for vintage column\n",
    "        df.shape[1]: for age column\n",
    "    \"\"\"\n",
    "    # df = df[['vintage','age']]\n",
    "    # Vintage\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    mask = df_.iloc[:,0] >= 7000\n",
    "    df_['vintage_score'] = df_.iloc[:,0]//1000 + 1\n",
    "    df_['vintage_score'][mask] = 8\n",
    "    \n",
    "    # age\n",
    "    cut_score = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    cut_bins = [0, 10, 19, 29, 39, 49, 59, 69, 100]\n",
    "    df_['age_score'] = pd.cut(df_.iloc[:,1], bins=cut_bins, labels=cut_score).astype(int)\n",
    "    df_['vintage_age_score'] = df_['vintage_score'] * df_['age_score']\n",
    "    # return 2D arrage required\n",
    "    return df_['vintage_age_score'].values.reshape(-1,1)\n",
    "\n",
    "# vintage_age score 2 - equal population\n",
    "def calculate_vintage_age_score_eqdens(df):\n",
    "    \"\"\" df: an array of shape (*,2)\n",
    "        df.shape[0]: for vintage column\n",
    "        df.shape[1]: for age column\n",
    "    \"\"\"\n",
    "    # df = df[['vintage','age']]\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    cut_score = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    df_['vintage_score'] = pd.qcut(df_.iloc[:,0], q=8, labels=cut_score).astype(int)\n",
    "    df_['age_score'] = pd.qcut(df_.iloc[:,1], q=8, labels=cut_score).astype(int)\n",
    "    df_['vintage_age_score'] = df_['vintage_score'] * df_['age_score']\n",
    "    # return 2D arrage required\n",
    "    return df_['vintage_age_score'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Convert custom functions into transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original features\n",
    "comb_cat_depend = FunctionTransformer(func=combine_cat, kw_args={'cutoff':6, 'replace':6}, validate=False)\n",
    "log_tsfm = FunctionTransformer(func=log_transform)\n",
    "impute_crdt_dbt = FunctionTransformer(func=impute_credit_debit)\n",
    "impute_bal = FunctionTransformer(func=impute_balance)\n",
    "\n",
    "# feature engineering\n",
    "pct_tsfm = FunctionTransformer(func=calculate_pct_change)\n",
    "ratio_tsfm = FunctionTransformer(func=calculate_ratio)\n",
    "seniority_tsfm_dist = FunctionTransformer(func=calculate_vintage_age_score_eqdist)\n",
    "seniority_tsfm_dens= FunctionTransformer(func=calculate_vintage_age_score_eqdens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_depend = Pipeline([('comb_depend',comb_cat_depend),\n",
    "                        ('imput_depend',SimpleImputer(strategy='constant',fill_value=1000)),\n",
    "                        ('ohe_depend',OneHotEncoder(handle_unknown='ignore',sparse=False))\n",
    "                       ])\n",
    "pipe_cat = Pipeline([('imput_cat',SimpleImputer(strategy='constant',fill_value='other')),\n",
    "                     ('ohe_cat',OneHotEncoder(handle_unknown='ignore',sparse=False))])\n",
    "# num_vars\n",
    "pipe_vin_age = Pipeline([('imput_base',SimpleImputer(strategy='median')),\n",
    "                      ('scal_base',StandardScaler()) ]) # vintage, age\n",
    "pipe_days = Pipeline([('imput_days',SimpleImputer(strategy='median')),\n",
    "                     ('log_days',log_tsfm),\n",
    "                     ('scal_days',StandardScaler())]) # days_since_last_transaction\n",
    "pipe_bal = Pipeline([('imput_bal',impute_bal),#AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                     ('log_bal',log_tsfm),\n",
    "                     ('scal_bal',StandardScaler())\n",
    "                    ])\n",
    "pipe_credit = Pipeline([('imput_credit', impute_crdt_dbt), #AmongFeaturesMeanImputer(features=credit_vars)),\n",
    "                     ('log_credit',log_tsfm),\n",
    "                     ('scal_credit',StandardScaler())]) # credit columns\n",
    "pipe_debit = Pipeline([('imput_debit',impute_crdt_dbt),\n",
    "                     ('log_debit',log_tsfm),\n",
    "                     ('scal_debit',StandardScaler())]) # debit columns\n",
    "# feature engineering\n",
    "pipe_pct = Pipeline([('imput_bal_pct',AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                     ('pct_chg',pct_tsfm),\n",
    "                     ('log_bal_pct',log_tsfm),\n",
    "                     ('scal_bal_pct',StandardScaler()) \n",
    "                    ]) # consecutive balance percent change\n",
    "pipe_vin_days = Pipeline([('imput_vinday',SimpleImputer(strategy='median')),\n",
    "                          ('ratio_vinday',ratio_tsfm), # df['days_since_last_transactio','vintage']\n",
    "                          ('scal_vinday',StandardScaler())\n",
    "                         ]) # vintage per days_since_last_transaction\n",
    "pipe_bal_person = Pipeline([('imput_bal_pers',AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                            ('ratio_bal_pers',ratio_tsfm), # df['dependents',balance columns]\n",
    "                            ('log_bal_pers',log_tsfm),\n",
    "                            ('scal_bal_pers',StandardScaler()) \n",
    "                           ]) # balance per person\n",
    "pipe_credit_person = Pipeline([('imput_credit_pers',AmongFeaturesMeanImputer(features=credit_vars)),\n",
    "                               ('ratio_credit_pers',ratio_tsfm), # df['dependents',credit columns]\n",
    "                               ('log_credit_pers',log_tsfm),\n",
    "                               ('scal_credit_pers',StandardScaler())]) # credit per person\n",
    "pipe_debit_person = Pipeline([('imput_debit',impute_crdt_dbt),\n",
    "                              ('ratio_debit_pers',ratio_tsfm), # df['dependents', debit columns]\n",
    "                              ('log_debit_pers',log_tsfm),\n",
    "                              ('scal_debit_pers',StandardScaler())]) # debit per person\n",
    "pipe_seniority = Pipeline([('imput_vinage',SimpleImputer(strategy='median')),                      \n",
    "                           ('sr_tsfm', seniority_tsfm_dens),\n",
    "                           ('scal_vinage',StandardScaler()) \n",
    "                          ]) # vintage, age]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_categories = [['Low','Medium','High']]\n",
    "pipeline_full = ColumnTransformer([\n",
    "            # categorical vars\n",
    "           ('depend', pipe_depend, depend), # 7 cols\n",
    "           ('cat_vars', pipe_cat, cat_vars), # 8 colc\n",
    "           ('ode_nw', OrdinalEncoder(categories=nw_categories), nw_cat), # 1 col\n",
    "           # numeric vars\n",
    "           ('vin_age', pipe_vin_age, vin_age_vars+['branch_code']), # 3 cols\n",
    "           #('vin_age', pipe_vin_age, vin_age_vars), # 2 cols\n",
    "           ('days', pipe_days, ['days_since_last_transaction']), # 1 col\n",
    "           ('num_bal', pipe_bal, bal_vars), # 6 cols\n",
    "           ('num_debit', pipe_debit, debit_vars), # 2 cols\n",
    "           ('num_credit', pipe_credit, credit_vars), # 2 cols\n",
    "           # engineered features\n",
    "           ('eng_pct',pipe_pct, bal_vars), # 5 cols\n",
    "           ('eng_vinday', pipe_vin_days, vin_day_vars), # 1 cols\n",
    "           ('eng_balpers', pipe_bal_person, depend+bal_vars), # 6 cols\n",
    "           ('eng_crdpers', pipe_credit_person, depend+credit_vars), # 2 cols\n",
    "           ('eng_dbtpers', pipe_debit_person, depend+debit_vars), # 2 cols\n",
    "           ('eng_srscore', pipe_seniority, vin_age_vars) #[vintage, age] # 1 cols\n",
    "  ]) #totla cols = 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_full.fit(X_train)\n",
    "X_train_transformed = pipeline_full.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13240, 47), (4414, 47))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "Next step is to feed the transformed data into models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
