{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning project -- Part 2  Build data Pipelines\n",
    "\n",
    "This project is to build a predictive machine learning model using the customer churn data available at Kaggle website. <br>\n",
    "Part 2 will look at building data pipelines that include engineering new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data nad split into train and test\n",
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (17654, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>vintage</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>occupation</th>\n",
       "      <th>customer_nw_category</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>days_since_last_transaction</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>previous_month_end_balance</th>\n",
       "      <th>average_monthly_balance_prevQ</th>\n",
       "      <th>average_monthly_balance_prevQ2</th>\n",
       "      <th>current_month_credit</th>\n",
       "      <th>previous_month_credit</th>\n",
       "      <th>current_month_debit</th>\n",
       "      <th>previous_month_debit</th>\n",
       "      <th>current_month_balance</th>\n",
       "      <th>previous_month_balance</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>23412.0</td>\n",
       "      <td>4767.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>High</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6853.27</td>\n",
       "      <td>6729.84</td>\n",
       "      <td>6724.64</td>\n",
       "      <td>7136.06</td>\n",
       "      <td>123.47</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6751.12</td>\n",
       "      <td>6729.84</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14012</th>\n",
       "      <td>19196.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Medium</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>22675.78</td>\n",
       "      <td>22479.53</td>\n",
       "      <td>23048.75</td>\n",
       "      <td>25045.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.63</td>\n",
       "      <td>512.91</td>\n",
       "      <td>417.31</td>\n",
       "      <td>22608.42</td>\n",
       "      <td>22953.98</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17344</th>\n",
       "      <td>23770.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Medium</td>\n",
       "      <td>239.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51661.42</td>\n",
       "      <td>21657.92</td>\n",
       "      <td>26622.51</td>\n",
       "      <td>14133.05</td>\n",
       "      <td>37931.86</td>\n",
       "      <td>5524.07</td>\n",
       "      <td>3942.13</td>\n",
       "      <td>16.04</td>\n",
       "      <td>46741.13</td>\n",
       "      <td>18545.29</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>575.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Low</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3368.08</td>\n",
       "      <td>2895.97</td>\n",
       "      <td>2969.17</td>\n",
       "      <td>2262.76</td>\n",
       "      <td>351.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3276.19</td>\n",
       "      <td>2892.05</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Low</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19286.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2562.23</td>\n",
       "      <td>1101.39</td>\n",
       "      <td>40714.94</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>7685.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id  vintage   age  gender  dependents  occupation  \\\n",
       "17084      23412.0   4767.0  78.0    Male         0.0      Lawyer   \n",
       "14012      19196.0   1519.0  35.0    Male         0.0  Accountant   \n",
       "17344      23770.0   1563.0  45.0    Male         0.0  Accountant   \n",
       "424          575.0   1215.0  76.0    Male         0.0      Lawyer   \n",
       "782         1086.0   1202.0  33.0  Female         0.0    Engineer   \n",
       "\n",
       "      customer_nw_category  branch_code  days_since_last_transaction  \\\n",
       "17084                 High       1336.0                          4.0   \n",
       "14012               Medium         20.0                         41.0   \n",
       "17344               Medium        239.0                          3.0   \n",
       "424                    Low       2615.0                         15.0   \n",
       "782                    Low       2710.0                          6.0   \n",
       "\n",
       "       current_balance  previous_month_end_balance  \\\n",
       "17084          6853.27                     6729.84   \n",
       "14012         22675.78                    22479.53   \n",
       "17344         51661.42                    21657.92   \n",
       "424            3368.08                     2895.97   \n",
       "782           19286.39                        0.66   \n",
       "\n",
       "       average_monthly_balance_prevQ  average_monthly_balance_prevQ2  \\\n",
       "17084                        6724.64                         7136.06   \n",
       "14012                       23048.75                        25045.84   \n",
       "17344                       26622.51                        14133.05   \n",
       "424                          2969.17                         2262.76   \n",
       "782                          2562.23                         1101.39   \n",
       "\n",
       "       current_month_credit  previous_month_credit  current_month_debit  \\\n",
       "17084                123.47                   0.04                 0.04   \n",
       "14012                  0.06                  15.63               512.91   \n",
       "17344              37931.86                5524.07              3942.13   \n",
       "424                  351.14                   0.46                 0.46   \n",
       "782                40714.94                   0.66                 0.66   \n",
       "\n",
       "       previous_month_debit  current_month_balance  previous_month_balance  \\\n",
       "17084                  0.04                6751.12                 6729.84   \n",
       "14012                417.31               22608.42                22953.98   \n",
       "17344                 16.04               46741.13                18545.29   \n",
       "424                    0.46                3276.19                 2892.05   \n",
       "782                    0.66                7685.39                    0.66   \n",
       "\n",
       "      churn  \n",
       "17084   Yes  \n",
       "14012   Yes  \n",
       "17344   Yes  \n",
       "424     Yes  \n",
       "782     Yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in data\n",
    "df0 = pd.read_csv('./data/visathon_train_data.csv')#,index=customer_id)\n",
    "print('Shape: {}'.format(df0.shape))\n",
    "df0.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "depend = ['dependents']\n",
    "cat_vars = ['gender', 'occupation']#,'branch_code']\n",
    "\n",
    "nw_cat = ['customer_nw_category']\n",
    "bal_vars = ['current_balance', 'current_month_balance', \n",
    "            'previous_month_end_balance','previous_month_balance',\n",
    "            'average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2']\n",
    "debit_vars = ['current_month_debit','previous_month_debit']\n",
    "credit_vars = ['current_month_credit', 'previous_month_credit']\n",
    "vin_age_vars = ['vintage', 'age']\n",
    "vin_day_vars = ['days_since_last_transaction','vintage']\n",
    "vin_dep_vars = ['dependents','vintage']\n",
    "\n",
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df0.drop(target,axis=1).copy()\n",
    "y = df0[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13240, 19)\n",
      "X_test shape: (4414, 19)\n",
      "y_train shape: (13240,)\n",
      "y_test shape: (4414,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=10086)\n",
    "print('X_train shape: {}\\nX_test shape: {}\\ny_train shape: {}\\ny_test shape: {}'.format( X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom functions\n",
    "### 1. Use BaseEstimator and TransformerMixin\n",
    "These transformers have been tested, can be used in the pipelines to replace corresponding tranformers from custom functions in following section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "## balance features\n",
    "class AmongFeaturesMeanImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column=[], features=[]):\n",
    "        \"\"\" column: feature to be imputed\n",
    "            features: features to for average values (can include column)\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        for feature in self.features:\n",
    "            X[feature].fillna(X[self.features].mean(axis=1,skipna=True),inplace=True)\n",
    "        return X\n",
    "\n",
    "# debit and credit features\n",
    "class FromFeatureImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=[]):\n",
    "        \"\"\" Column: feature to be imputed\n",
    "            feature: feature to provide value\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "#         self.column = column\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        print(self.features)\n",
    "        print([self.features[0]])\n",
    "        print(self.features + [self.features[0]])\n",
    "        feature_list = self.features + [self.features[0]]\n",
    "        for i, feature in enumerate(feature_list):\n",
    "            if i < len(feature_list)-1:\n",
    "                X[feature] = X[feature].fillna(X[feature_list[i+1]]*(1+np.random.randn()))\n",
    "        return X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define custom tranformation functions\n",
    "#### 1) Impute and log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine non-frequent categories into one\n",
    "def combine_cat(s, cutoff=6, replace=6):\n",
    "    \"\"\" Replace the categories that are greater than or equal to the cutoff with replace\n",
    "        s: a Pandas series\n",
    "        cutoff: a scalar\n",
    "        cat: scalar\n",
    "        \n",
    "        return: a series with replaced values\n",
    "    \"\"\"\n",
    "    s_ = s.copy()\n",
    "    mask = s > cutoff\n",
    "    s_[mask==True] = replace\n",
    "    return s_\n",
    "\n",
    "# balance, debit, credit, days_since_last_transaction\n",
    "def log_transform(df):\n",
    "    \"\"\" Log transform the values in the df.\n",
    "            for values < 0, log tranform absolute value, and then reverse to negative.\n",
    "        df: a panda dataframe or array like.\n",
    "        \n",
    "        return: a pandas dataframe with log transformed values\n",
    "    \"\"\"\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    s_= []\n",
    "    for i in range(df.shape[1]):\n",
    "        s_.append([np.log(x+1) if x>=0 else -np.log(-x+1) for x in df_.iloc[:,i]])\n",
    "    s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_\n",
    "\n",
    "## balance features\n",
    "def impute_balance(df):\n",
    "    \"\"\" Fill in missing values in each column with the average value of other columns in the same row\n",
    "        df: a panda dataframe. To be imputed.\n",
    "        \n",
    "        return: a pandas dataframe without missing values\n",
    "    \"\"\"\n",
    "    s_= []\n",
    "    for i in range(df.shape[1]):\n",
    "        s = df.iloc[:,i] \n",
    "        s_.append(s.fillna(df.mean(axis=1,skipna=True)))\n",
    "    s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_\n",
    "\n",
    "# debit and credit features\n",
    "def impute_credit_debit(df):\n",
    "    \"\"\" Fill in missing values in each column with the average value of other columns in the same row\n",
    "            then add some randomness to the replacement value.\n",
    "        df: a panda dataframe. To be imputed.\n",
    "        \n",
    "        return: a pandas dataframe without missing values\n",
    "    \"\"\"\n",
    "    s_= []\n",
    "    for i in range(df.shape[1]):\n",
    "        s = df.iloc[:,i] \n",
    "        s_.append(s.fillna(df.mean(axis=1)*(1+np.random.randn())))\n",
    "    s_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return s_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Engineer new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Engineer new features \n",
    "# percentage changes\n",
    "def calculate_pct_change(df):\n",
    "    \"\"\" calculate percent changes in balance between consecutive periods\n",
    "        df: Pandas dataframe or array. Balance columns of two consecutive peroids\n",
    "        \n",
    "        return: a dataframe containing percent changes with one less number of columns.\n",
    "    \"\"\"\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    s_ = []\n",
    "    for i in range(df_.shape[1]-1):\n",
    "        s1 = df_.iloc[:,i]\n",
    "        s2 = df_.iloc[:,i+1]\n",
    "        s_.append((s1-s2)/(s2+1)*100) # s2+1 to avoid dividing-by-zero\n",
    "    df_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return df_ \n",
    "\n",
    "# vintage/(day_since_last_transaction) & per person values in a household\n",
    "def calculate_ratio(df):\n",
    "    \"\"\" calculate the ratio of two features. First column is denominator\n",
    "        df: Pandas dataframe or numpy array.\n",
    "        \n",
    "        return: a dataframe containing ratio with one less number of columns.\n",
    "    \"\"\"\n",
    "    s_ = []\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    s1 = df_.iloc[:,0]\n",
    "    for i in range(1,df_.shape[1]):\n",
    "        s2 = df_.iloc[:,i]\n",
    "        s_.append(s2/(s1+1)) #to avoid dividing by zero\n",
    "    df_ = pd.DataFrame.from_records(s_).transpose()\n",
    "    return df_ \n",
    "\n",
    "# vintage_age score 1 - equal distance\n",
    "def calculate_vintage_age_score_eqdist(df):\n",
    "    \"\"\" Calculate vintage-age combined score with equal-distance bins (pd.cut)\n",
    "        df: an array of shape (*,2) or a dataframe\n",
    "            df.shape[0]: for vintage column\n",
    "            df.shape[1]: for age column\n",
    "        \n",
    "        return: a 2D array (shape (*,1)) withe the scores\n",
    "    \"\"\"\n",
    "    # df = df[['vintage','age']]\n",
    "    # Vintage\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    mask = df_.iloc[:,0] >= 7000\n",
    "    df_['vintage_score'] = df_.iloc[:,0]//1000 + 1\n",
    "    df_['vintage_score'][mask] = 8\n",
    "    \n",
    "    # age\n",
    "    cut_score = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    cut_bins = [0, 10, 19, 29, 39, 49, 59, 69, 100]\n",
    "    df_['age_score'] = pd.cut(df_.iloc[:,1], bins=cut_bins, labels=cut_score).astype(int)\n",
    "    df_['vintage_age_score'] = df_['vintage_score'] * df_['age_score']\n",
    "    # return 2D arrage required\n",
    "    return df_['vintage_age_score'].values.reshape(-1,1)\n",
    "\n",
    "# vintage_age score 2 - equal population\n",
    "def calculate_vintage_age_score_eqdens(df):\n",
    "    \"\"\" Calculate vintage-age combined score with equal-population bins (pd.qcut)\n",
    "        df: an array of shape (*,2) or a dataframe\n",
    "            df.shape[0]: for vintage column\n",
    "            df.shape[1]: for age column\n",
    "        \n",
    "        return: a 2D array (shape (*,1)) withe the scores\n",
    "    \"\"\"\n",
    "    # df = df[['vintage','age']]\n",
    "    df_ = pd.DataFrame(df.copy())\n",
    "    cut_score = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    df_['vintage_score'] = pd.qcut(df_.iloc[:,0], q=8, labels=cut_score).astype(int)\n",
    "    df_['age_score'] = pd.qcut(df_.iloc[:,1], q=8, labels=cut_score).astype(int)\n",
    "    df_['vintage_age_score'] = df_['vintage_score'] * df_['age_score']\n",
    "    # return 2D arrage required\n",
    "    return df_['vintage_age_score'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Convert custom functions into transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original features\n",
    "comb_cat_depend = FunctionTransformer(func=combine_cat, kw_args={'cutoff':6, 'replace':6}, validate=False)\n",
    "log_tsfm = FunctionTransformer(func=log_transform)\n",
    "impute_crdt_dbt = FunctionTransformer(func=impute_credit_debit)\n",
    "impute_bal = FunctionTransformer(func=impute_balance)\n",
    "\n",
    "# feature engineering\n",
    "pct_tsfm = FunctionTransformer(func=calculate_pct_change)\n",
    "ratio_tsfm = FunctionTransformer(func=calculate_ratio)\n",
    "seniority_tsfm_dist = FunctionTransformer(func=calculate_vintage_age_score_eqdist)\n",
    "seniority_tsfm_dens= FunctionTransformer(func=calculate_vintage_age_score_eqdens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_depend = Pipeline([('comb_depend',comb_cat_depend),\n",
    "                        ('imput_depend',SimpleImputer(strategy='constant',fill_value=1000)),\n",
    "                        ('ohe_depend',OneHotEncoder(handle_unknown='ignore',sparse=False))\n",
    "                       ])\n",
    "pipe_cat = Pipeline([('imput_cat',SimpleImputer(strategy='constant',fill_value='other')),\n",
    "                     ('ohe_cat',OneHotEncoder(handle_unknown='ignore',sparse=False))])\n",
    "# num_vars\n",
    "pipe_vin_age = Pipeline([('imput_base',SimpleImputer(strategy='median')),\n",
    "                      ('scal_base',StandardScaler()) ]) # vintage, age\n",
    "pipe_days_br = Pipeline([('imput_days_br',SimpleImputer(strategy='median')),\n",
    "                     ('log_days_br',log_tsfm),\n",
    "#                      ('scal_days_br',StandardScaler())\n",
    "                        ]) # days_since_last_transaction\n",
    "pipe_bal = Pipeline([('imput_bal',impute_bal),#AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                     ('log_bal',log_tsfm),\n",
    "                     ('scal_bal',StandardScaler())\n",
    "                    ])\n",
    "pipe_credit = Pipeline([('imput_credit', impute_crdt_dbt), #AmongFeaturesMeanImputer(features=credit_vars)),\n",
    "                     ('log_credit',log_tsfm),\n",
    "                     ('scal_credit',StandardScaler())]) # credit columns\n",
    "pipe_debit = Pipeline([('imput_debit',impute_crdt_dbt),\n",
    "                     ('log_debit',log_tsfm),\n",
    "                     ('scal_debit',StandardScaler())]) # debit columns\n",
    "# feature engineering\n",
    "pipe_pct = Pipeline([('imput_bal_pct', impute_bal), #AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                     ('pct_chg',pct_tsfm),\n",
    "                     ('log_bal_pct',log_tsfm),\n",
    "                     ('scal_bal_pct',StandardScaler()) \n",
    "                    ]) # consecutive balance percent change\n",
    "pipe_vin_days = Pipeline([('imput_vinday',SimpleImputer(strategy='median')),\n",
    "                          ('ratio_vinday',ratio_tsfm), # df['days_since_last_transactio','vintage']\n",
    "                          ('scal_vinday',StandardScaler())\n",
    "                         ]) # vintage per days_since_last_transaction\n",
    "pipe_bal_person = Pipeline([('imput_bal_pers', impute_bal), #AmongFeaturesMeanImputer(features=bal_vars)),\n",
    "                            ('ratio_bal_pers',ratio_tsfm), # df['dependents',balance columns]\n",
    "                            ('log_bal_pers',log_tsfm),\n",
    "                            ('scal_bal_pers',StandardScaler()) \n",
    "                           ]) # balance per person\n",
    "pipe_credit_person = Pipeline([('imput_credit_pers', impute_crdt_dbt), #AmongFeaturesMeanImputer(features=credit_vars)),\n",
    "                               ('ratio_credit_pers',ratio_tsfm), # df['dependents',credit columns]\n",
    "                               ('log_credit_pers',log_tsfm),\n",
    "                               ('scal_credit_pers',StandardScaler())]) # credit per person\n",
    "pipe_debit_person = Pipeline([('imput_debit',impute_crdt_dbt),\n",
    "                              ('ratio_debit_pers',ratio_tsfm), # df['dependents', debit columns]\n",
    "                              ('log_debit_pers',log_tsfm),\n",
    "                              ('scal_debit_pers',StandardScaler())]) # debit per person\n",
    "pipe_seniority = Pipeline([('imput_vinage',SimpleImputer(strategy='median')),                      \n",
    "                           ('sr_tsfm', seniority_tsfm_dens),\n",
    "                           ('scal_vinage',StandardScaler()) \n",
    "                          ]) # vintage, age]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_categories = [['Low','Medium','High']]\n",
    "pipeline_data = ColumnTransformer([\n",
    "            # categorical vars\n",
    "           ('depend', pipe_depend, depend), # 7 cols\n",
    "           ('cat_vars', pipe_cat, cat_vars), # 8 colc\n",
    "           ('ode_nw', OrdinalEncoder(categories=nw_categories), nw_cat), # 1 col\n",
    "           # numeric vars\n",
    "           ('vin_age', pipe_vin_age, vin_age_vars), # 2 cols\n",
    "           ('days_br', pipe_days_br, ['days_since_last_transaction','branch_code']), # 2 col\n",
    "           ('num_bal', pipe_bal, bal_vars), # 6 cols\n",
    "           ('num_debit', pipe_debit, debit_vars), # 2 cols\n",
    "           ('num_credit', pipe_credit, credit_vars), # 2 cols\n",
    "           # engineered features\n",
    "           ('eng_pct',pipe_pct, bal_vars), # 5 cols\n",
    "           ('eng_vinday', pipe_vin_days, vin_day_vars), # 1 cols\n",
    "           ('eng_balpers', pipe_bal_person, depend+bal_vars), # 6 cols\n",
    "           ('eng_crdpers', pipe_credit_person, depend+credit_vars), # 2 cols\n",
    "           ('eng_dbtpers', pipe_debit_person, depend+debit_vars), # 2 cols\n",
    "           ('eng_srscore', pipe_seniority, vin_age_vars) #[vintage, age] # 1 cols\n",
    "  ]) #totla cols = 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit-Transform datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data.fit(X_train)\n",
    "X_train_transformed = pipeline_data.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline_data.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13240, 47), (4414, 47))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(pipeline_data,'pipeline_data.joblib')\n",
    "pipeline_data = joblib.load('pipeline_data.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step\n",
    "Next step is to feed the transformed data into models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
